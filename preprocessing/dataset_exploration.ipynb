{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration\n",
    "This notebook serves to dive deeper into the properties of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories we will need\n",
    "git_root = Path('..')\n",
    "data_root = git_root / 'data'\n",
    "assert data_root.exists()\n",
    "\n",
    "# dataset split files\n",
    "b1_train_path = data_root / 'splits' / 'batch1_training_filtered.tsv'\n",
    "b1_val_path = data_root / 'splits' / 'batch1_val_filtered.tsv'\n",
    "b1_test_path = data_root / 'splits' / 'batch1_test_filtered.tsv'\n",
    "b2_train_path = data_root / 'splits' / 'batch2_training_filtered.tsv'\n",
    "b2_val_path = data_root / 'splits' / 'batch2_val_filtered.tsv'\n",
    "b2_test_path = data_root / 'splits' / 'batch2_test_filtered.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_full_data = data_root / 'preprocessing' / 'classification_median_batch_1.tsv'\n",
    "b2_full_data = data_root / 'preprocessing' / 'classification_median_batch_2.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barcode - gene pairs\n",
    "Previously, we noticed during embedding calculation, that not all barcodes have targets/labels all genes, which is required for supervised learning. \n",
    "Thus, we analyse the barcode - gene pairs in the data here.\n",
    "In particular, we want to identify the minimal gene set, that is shared among all barcodes of a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algoritm idea make iterative intersections.\n",
    "# 1. start will a set of all uniq genes\n",
    "# 2. for each uniq barcode intersect the uniq gene ids associated to this barcode\n",
    "# 3. return the result of all intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimal_gene_set(df: pd.DataFrame):\n",
    "    uniq_gene_ids = set(df['gene_id'])\n",
    "    uniq_barodes = set(df['barcode'])\n",
    "    minimal_gene_set = uniq_gene_ids\n",
    "    for barcode in uniq_barodes:\n",
    "        minimal_gene_set = minimal_gene_set.intersection(\n",
    "            set(df[df['barcode'] == barcode]['gene_id'])\n",
    "        )\n",
    "    return minimal_gene_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENSG00000186047',\n",
       " 'ENSG00000188001',\n",
       " 'ENSG00000233008',\n",
       " 'ENSG00000154485',\n",
       " 'ENSG00000196787',\n",
       " 'ENSG00000287200',\n",
       " 'ENSG00000224982',\n",
       " 'ENSG00000130844',\n",
       " 'ENSG00000152583',\n",
       " 'ENSG00000053254']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_gene_ids = set(b1_df['gene_id'])\n",
    "len(uniq_gene_ids)\n",
    "list(uniq_gene_ids)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACCCTGTTCCAGGAAA-1',\n",
       " 'TATATCCTCCTGGTCT-1',\n",
       " 'TTCGGTACAAATTGCT-1',\n",
       " 'GTACTGGTCATGTGGT-1',\n",
       " 'CTTGCGCGTTTATGGG-1',\n",
       " 'GCACTAAGTTTACGTC-1',\n",
       " 'GCCTTAACATTGACAT-1',\n",
       " 'TGAAGGATCATTTGCT-1',\n",
       " 'CTCCTGAGTTGTGACA-1',\n",
       " 'TTAAGTGTCAGGTCCA-1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_barodes = set(b1_df['barcode'])\n",
    "len(uniq_barodes)\n",
    "list(uniq_barodes)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_gene_overlap = uniq_gene_ids\n",
    "for barcode in uniq_barodes:\n",
    "    minimal_gene_overlap = minimal_gene_overlap.intersection(\n",
    "        set(b1_df[b1_df['barcode'] == barcode]['gene_id'])\n",
    "    )\n",
    "len(minimal_gene_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_min_gene_set = find_minimal_gene_set(\n",
    "    b1_df = pd.read_csv(b1_full_data, sep='\\t')\n",
    ")\n",
    "len(b1_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In vestigate minimal gene set for batch 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_df = pd.read_csv(b2_full_data, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_min_gene_set = find_minimal_gene_set(b2_df)\n",
    "len(b2_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal gene set of splits\n",
    "As we see, the minimal gene overlap contains all 2000 genes we selected for our analysis.\n",
    "Thus, check if the error arrises from the split data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch 1 train\n",
    "Minimal gene overlap set for training split of batch 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_train_min_gene_set = find_minimal_gene_set(\n",
    "    pd.read_csv(b1_train_path, sep='\\t')\n",
    ")\n",
    "len(b1_train_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch 1 validation\n",
    "Minimal gene overlap set for training split of batch 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_val_min_gene_set = find_minimal_gene_set(\n",
    "    pd.read_csv(b1_val_path, sep='\\t')\n",
    ")\n",
    "len(b1_val_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch 1 test\n",
    "Minimal gene overlap set for training split of batch 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_test_min_gene_set = find_minimal_gene_set(\n",
    "    pd.read_csv(b1_test_path, sep='\\t')\n",
    ")\n",
    "len(b1_test_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch 2 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_train_min_gene_set = find_minimal_gene_set(\n",
    "    pd.read_csv(b2_train_path, sep='\\t')\n",
    ")\n",
    "len(b2_train_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch 2 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_val_min_gene_set = find_minimal_gene_set(\n",
    "    pd.read_csv(b2_val_path, sep='\\t')\n",
    ")\n",
    "len(b2_val_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch 2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_test_min_gene_set = find_minimal_gene_set(\n",
    "    pd.read_csv(b2_test_path, sep='\\t')\n",
    ")\n",
    "len(b2_test_min_gene_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class\n",
    "This section tests the dataset class `CnvDataset` from `src/data/dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # add the parent directory to system path\n",
    "from src.data.dataset import CnvDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File format benchmark\n",
    "We discussed multiple file formats to use in the backend for storing computed embeddings on the disk. Suggestions were the vanilla pytorch format `.pt`, pickle files `.pkl` and the scipy matrix format `.mtx`.\n",
    "Since pytorch is using pickle in the backend for creating `.pt` files, we decided to only use the `.pt` and `.mtx` formats.\n",
    "In the following we benchmark reading from these file types, as this could be a bottleneck during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_val_path = data_root / 'splits' / 'batch1_val_filtered.tsv'\n",
    "b1_val_dataset = CnvDataset(\n",
    "    root=data_root / 'embeddings' / 'batch_1' / 'val',\n",
    "    data_df=pd.read_csv(b1_val_path, sep='\\t'),\n",
    "    embedding_mode='single_gene_barcode',\n",
    "    file_format='mtx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_val_path = data_root / 'splits' / 'batch2_val_filtered.tsv'\n",
    "b2_val_dataset = CnvDataset(\n",
    "    root=data_root / 'embeddings' / 'batch_2',\n",
    "    data_df=pd.read_csv(b2_val_path, sep='\\t'),\n",
    "    embedding_mode='single_gene_barcode',\n",
    "    file_format='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/embeddings/batch_1/val/single_gene_barcode/AAAGGTTAGGGTGGAT-1/ENSG00000117984.mtx\n",
      "../data/embeddings/batch_2/single_gene_barcode/AAACCAACATTGCGGT-2/ENSG00000172985.pt\n"
     ]
    }
   ],
   "source": [
    "b1_test_path = b1_val_dataset.data_df['embedding_path'].iloc[42]\n",
    "b2_test_path = b2_val_dataset.data_df['embedding_path'].iloc[42]\n",
    "print(b1_test_path)\n",
    "print(b2_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import load as pyt_load\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.93 ms ± 40.5 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t = mmread(b1_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 μs ± 646 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t = pyt_load(b2_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.16 ms ± 204 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t = b1_val_dataset[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 μs ± 25.1 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "t = b2_val_dataset[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, using the `mtx` format is `# samples * # iterations * 1000 μs` longer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
