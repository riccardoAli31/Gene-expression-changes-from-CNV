{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Tutorial\n",
    "This notebook gives a short tutorial on how to use the pytorch dataset I implemented.\n",
    "You find the code in `src/data/dataset.py` in the `CnvDataset` class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start by importing some packages we might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# add this to you notebook so it automatically reloads code you changed in a\n",
    "# python file after importing this code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also need to import the `CnvDataset` class.\n",
    "Since the path (relative to the git repository root) to this notebook is `preprocessing/dataset_example.ipynb`, we need to add the parent directory to our system path in order to import software from there.\n",
    "Think of it like this: We need to tell the notebook the relative path to the software folder `src` in order to import software from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # add the parent directory to system path\n",
    "from src.data.dataset import CnvDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great :)\n",
    "Now that this is out of the way, let's define some important paths for files we need to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories we will need\n",
    "git_root = Path('..')\n",
    "data_root = git_root / 'data'\n",
    "assert data_root.exists()\n",
    "\n",
    "# dataset split files\n",
    "b1_train_path = data_root / 'splits' / 'batch1_training_filtered.tsv'\n",
    "b1_val_path = data_root / 'splits' / 'batch1_val_filtered.tsv'\n",
    "b1_test_path = data_root / 'splits' / 'batch1_test_filtered.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we are almost ready to use the `CnvDataset`.\n",
    "One last thing thats is missing, is the path to the directory that stores the embedding files for the dataset we want to use.\n",
    "All dataset paths follow the same pattern:\n",
    "```\n",
    "data/embeddings/batch_<batch_number>/<dataset_type>/<embedding_mode>\n",
    "```\n",
    "where:\n",
    "* `batch_<batch_number>` is either `batch_1` or `batch_2`\n",
    "* `<dataset_type>` is one of `train`, `val` or `test`\n",
    "* `<embedding_mode>` is one of `single_gene_barcode`, `gene_concat` or `barcode_channel`\n",
    "\n",
    "Please note, that the `<embedding_mode>` will be added automatically.\n",
    "You don't need to add it to the dataset path, just change the `embedding_mode` parameter for the `CnvDataset` class.\n",
    "Also, please make sure that the directory actually exists.\n",
    "However, the python code will raise an exception if does not find any embedding files.\n",
    "\n",
    "OK. Now let's define the dataset we want to use.\n",
    "In this example I chose the validation set of batch 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/embeddings/batch_1/validation')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root = data_root / 'embeddings' / 'batch_1' / 'val'\n",
    "dataset_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read the validation split data frame using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>expression_count</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAGGTTAGGGTGGAT-1</td>\n",
       "      <td>ENSG00000173372</td>\n",
       "      <td>0.407756</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAGGTTAGGGTGGAT-1</td>\n",
       "      <td>ENSG00000226476</td>\n",
       "      <td>1.103188</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAGGTTAGGGTGGAT-1</td>\n",
       "      <td>ENSG00000231252</td>\n",
       "      <td>1.257665</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAGGTTAGGGTGGAT-1</td>\n",
       "      <td>ENSG00000229956</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAGGTTAGGGTGGAT-1</td>\n",
       "      <td>ENSG00000188641</td>\n",
       "      <td>0.407756</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>TTGGCTACATAAGTTC-1</td>\n",
       "      <td>ENSG00000198938</td>\n",
       "      <td>2.065108</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8950</th>\n",
       "      <td>TTGGCTACATAAGTTC-1</td>\n",
       "      <td>ENSG00000198840</td>\n",
       "      <td>1.721116</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8951</th>\n",
       "      <td>TTGGCTACATAAGTTC-1</td>\n",
       "      <td>ENSG00000198886</td>\n",
       "      <td>2.611877</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8952</th>\n",
       "      <td>TTGGCTACATAAGTTC-1</td>\n",
       "      <td>ENSG00000198786</td>\n",
       "      <td>1.907831</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>TTGGCTACATAAGTTC-1</td>\n",
       "      <td>ENSG00000198727</td>\n",
       "      <td>1.721116</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8954 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 barcode          gene_id  expression_count classification\n",
       "0     AAAGGTTAGGGTGGAT-1  ENSG00000173372          0.407756            low\n",
       "1     AAAGGTTAGGGTGGAT-1  ENSG00000226476          1.103188           high\n",
       "2     AAAGGTTAGGGTGGAT-1  ENSG00000231252          1.257665           high\n",
       "3     AAAGGTTAGGGTGGAT-1  ENSG00000229956          0.696581            low\n",
       "4     AAAGGTTAGGGTGGAT-1  ENSG00000188641          0.407756            low\n",
       "...                  ...              ...               ...            ...\n",
       "8949  TTGGCTACATAAGTTC-1  ENSG00000198938          2.065108           high\n",
       "8950  TTGGCTACATAAGTTC-1  ENSG00000198840          1.721116           high\n",
       "8951  TTGGCTACATAAGTTC-1  ENSG00000198886          2.611877           high\n",
       "8952  TTGGCTACATAAGTTC-1  ENSG00000198786          1.907831           high\n",
       "8953  TTGGCTACATAAGTTC-1  ENSG00000198727          1.721116           high\n",
       "\n",
       "[8954 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_val_path = data_root / 'splits' / 'batch1_val_filtered.tsv'\n",
    "b1_val_df = pd.read_csv(b1_val_path, sep='\\t')\n",
    "b1_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 51 barcodes\n",
      "Using 1093 genes\n",
      "No embedding files for 988 data points in ../data/embeddings/batch_1/validation/single_gene_barcode!\n"
     ]
    }
   ],
   "source": [
    "b1_val_dataset = CnvDataset(\n",
    "    root=dataset_root,\n",
    "    data_df=b1_val_df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look something like:\n",
    "```\n",
    "Using 51 barcodes\n",
    "Using 1093 genes\n",
    "No embedding files for 932 data points in ../data/embeddings/batch_1/val/single_gene_barcode!\n",
    "```\n",
    "\n",
    "This means that from the datapoint with target values in the dataset, we are missing 932 embedding files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to get the number of data points and the first rows of the data frame by using the string representaiton of the dataset variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.data.dataset.CnvDataset'> with 7966 datapoints\n",
      "              barcode          gene_id  expression_count classification  \\\n",
      "0  AAAGGTTAGGGTGGAT-1  ENSG00000173372          0.407756            low   \n",
      "1  AAAGGTTAGGGTGGAT-1  ENSG00000226476          1.103188           high   \n",
      "2  AAAGGTTAGGGTGGAT-1  ENSG00000231252          1.257665           high   \n",
      "3  AAAGGTTAGGGTGGAT-1  ENSG00000229956          0.696581            low   \n",
      "4  AAAGGTTAGGGTGGAT-1  ENSG00000188641          0.407756            low   \n",
      "\n",
      "                                      embedding_path  \n",
      "0  ../data/embeddings/batch_1/validation/single_g...  \n",
      "1  ../data/embeddings/batch_1/validation/single_g...  \n",
      "2  ../data/embeddings/batch_1/validation/single_g...  \n",
      "3  ../data/embeddings/batch_1/validation/single_g...  \n",
      "4  ../data/embeddings/batch_1/validation/single_g...  \n"
     ]
    }
   ],
   "source": [
    "print(str(b1_val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we should be able to get the embedding and the classification label from the dataset using an index (just like a list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.,  ..., 1., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "embedding, target = b1_val_dataset[0]\n",
    "print(type(embedding))\n",
    "print(type(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the dataset for regression you need to set the `target_type` parameter for the `CnvDataset` class to `'regression'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 51 barcodes\n",
      "Using 1093 genes\n",
      "No embedding files for 932 data points in ../data/embeddings/batch_1/val/single_gene_barcode!\n"
     ]
    }
   ],
   "source": [
    "b1_val_dataset = CnvDataset(\n",
    "    root=dataset_root,\n",
    "    data_df=b1_val_df,\n",
    "    target_type='regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [0., 1., 0.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_val_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the training set for a regression use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 356 barcodes\n",
      "Using 1595 genes\n",
      "No embedding files for 4335 data points in ../data/embeddings/batch_1/train/single_gene_barcode!\n"
     ]
    }
   ],
   "source": [
    "b1_train_path = data_root / 'splits' / 'batch1_training_filtered.tsv'\n",
    "train_set_root = data_root / 'embeddings' / 'batch_1' / 'train'\n",
    "b1_train_df = pd.read_csv(b1_train_path, sep='\\t')\n",
    "b1_train_dataset = CnvDataset(\n",
    "    root=train_set_root,\n",
    "    data_df=b1_train_df,\n",
    "    target_type='regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'src.data.dataset.CnvDataset'> with 55006 datapoints"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 1., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([0.7499]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_train_dataset[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here a example using the test dataset for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 102 barcodes\n",
      "Using 1235 genes\n",
      "No embedding files for 3795 data points in ../data/embeddings/batch_1/test/single_gene_barcode!\n"
     ]
    }
   ],
   "source": [
    "test_set_root = data_root / 'embeddings' / 'batch_1' / 'test'\n",
    "b1_test_df = pd.read_csv(b1_test_path, sep='\\t')\n",
    "b1_test_dataset = CnvDataset(\n",
    "    root=test_set_root,\n",
    "    data_df=b1_test_df,\n",
    "    target_type='regression'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'src.data.dataset.CnvDataset'> with 14840 datapoints"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over the Dataset\n",
    "There are two common ways to iterate over a Dataset.\n",
    "1. use a for-loop over the dataset\n",
    "2. use a for-loop over `range(len(dataset))` and get the data point per index.\n",
    "3. use a DataLoader from `pytorch.utils.data.DataLoader`.\n",
    "\n",
    "Let's start by using the same dataset as in the beginning of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 51 barcodes\n",
      "Using 1093 genes\n",
      "No embedding files for 988 data points in ../data/embeddings/batch_1/validation/single_gene_barcode!\n"
     ]
    }
   ],
   "source": [
    "# this time I am specifically requsting numpy results from the dataset\n",
    "b1_val_dataset = CnvDataset(\n",
    "    root=data_root / 'embeddings' / 'batch_1' / 'val',\n",
    "    data_df=pd.read_csv(data_root / 'splits' / 'batch1_val_filtered.tsv', sep='\\t'),\n",
    "    return_numpy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start by making a for loop over the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2990  2003  1999  3008     0 10000     0]\n",
      "[ 7168  7450  7334  7113 10000     0     0]\n",
      "[4260 4412 4196 4284 1822    0    0]\n",
      "[ 2312  2492  2553  2643 10000     0     0]\n",
      "[ 2789  2188  2130  2893     0     0 10000]\n",
      "[ 2976  1906  1958  3160     0     0 10000]\n",
      "[2998 3817 4065 3152 2488    0    0]\n",
      "[2641 2308 2475 2576 1748    0    0]\n"
     ]
    }
   ],
   "source": [
    "# this code prints the row sum for the first 8 embeddings with either ATAC,\n",
    "#  CNV loss or CNV gain\n",
    "i = 0\n",
    "for embedding, target in b1_val_dataset:\n",
    "    t_sum = embedding.sum(axis=1)\n",
    "    if any(t_sum[4:] > 0):\n",
    "        i += 1\n",
    "        print(t_sum)\n",
    "    if i > 7:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's use the the index specific access with a range in the for loop.\n",
    "This you can also use to iterate over a specific set of indices in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 10000)\n",
      "[1.]\n",
      "(7, 10000)\n",
      "[0.]\n",
      "(7, 10000)\n",
      "[0.]\n",
      "(7, 10000)\n",
      "[0.]\n",
      "(7, 10000)\n",
      "[1.]\n",
      "(7, 10000)\n",
      "[0.]\n",
      "(7, 10000)\n",
      "[0.]\n",
      "(7, 10000)\n",
      "[0.]\n",
      "(7, 10000)\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "start = 42\n",
    "for i in range(start, len(b1_val_dataset)):\n",
    "    embedding, target = b1_val_dataset[i]\n",
    "    print(embedding.shape)\n",
    "    print(target)\n",
    "    if i > 7 + start:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, you can use a `pytorch.utils.data.DataLoader` to iterate through the dataset.\n",
    "This is possible, because the `CnvDataset` class inherits from `pytorch.utils.data.Dataset`.\n",
    "See an example usage of a dataloader below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the batch size determines the group size per iteration\n",
    "b1_val_loader = DataLoader(b1_val_dataset, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 7, 10000])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(b1_val_loader):\n",
    "    embeddings, targets = batch\n",
    "    print(embeddings.shape)\n",
    "    print(targets.shape)\n",
    "    if i > 7:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even though `CnvDataset` returns numpy arrays, the Dataloader converts thess into pytorch tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Embeddings from scratch\n",
    "\n",
    "> **Warning**:\n",
    "> Recomputing embeddings from scratch is time consuming.\n",
    "> We reccomend either using a very small dataset or using \"no-hangup\" mechanism like a `screen` session or the `nohup` command in the terminal. \n",
    "\n",
    "This section covers (re-)computing embeddings using the `CnvDataset`.\n",
    "For this we need a little bit more information than before.\n",
    "Like previouly, let's start by defining some paths to relevant files and directories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories we will need\n",
    "out_root = git_root / 'out'\n",
    "\n",
    "# files we will need\n",
    "genome_fasta = data_root / 'reference' / 'GRCh38.d1.vd1.fa'\n",
    "assert genome_fasta.exists()\n",
    "gtf_path=data_root / 'gene_positions_and_overlaps' / 'gene_positions.csv'\n",
    "assert gtf_path.exists()\n",
    "overlap_path = data_root / 'gene_positions_and_overlaps' / 'overlaps_batch1.tsv'\n",
    "assert overlap_path.exists()\n",
    "epiAneufinder_path = out_root / 'epiAneufinder' / 'epiAneuFinder_results.tsv'\n",
    "assert epiAneufinder_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_train_path = data_root / 'splits' / 'batch2_training_filtered.tsv'\n",
    "b2_val_path = data_root / 'splits' / 'batch2_val_filtered.tsv'\n",
    "b2_test_path = data_root / 'splits' / 'batch2_test_filtered.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load as a illustration dataset the first 42 rows from the batch 2 validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>expression_count</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000162512</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000186094</td>\n",
       "      <td>1.850096</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000231252</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000183023</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000115355</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000172005</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000172985</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000152127</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000157827</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000236283</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000057019</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000283154</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000144959</td>\n",
       "      <td>1.850096</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000169760</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000002587</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000250137</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000184305</td>\n",
       "      <td>1.850096</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000109323</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000287292</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000112902</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000113361</td>\n",
       "      <td>2.603257</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000185305</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000069020</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000145819</td>\n",
       "      <td>2.295968</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000228412</td>\n",
       "      <td>1.850096</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000112576</td>\n",
       "      <td>1.850096</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000177706</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000106415</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000105855</td>\n",
       "      <td>3.325113</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000136237</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000287523</td>\n",
       "      <td>2.461370</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000106258</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000081800</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000196511</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000253773</td>\n",
       "      <td>1.520305</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000253438</td>\n",
       "      <td>2.097679</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000269900</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000226337</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000119125</td>\n",
       "      <td>2.097679</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000107611</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000197746</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AAACCAACATTGCGGT-2</td>\n",
       "      <td>ENSG00000185737</td>\n",
       "      <td>1.024897</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               barcode          gene_id  expression_count classification\n",
       "0   AAACCAACATTGCGGT-2  ENSG00000162512          1.024897           high\n",
       "1   AAACCAACATTGCGGT-2  ENSG00000186094          1.850096           high\n",
       "2   AAACCAACATTGCGGT-2  ENSG00000231252          1.024897           high\n",
       "3   AAACCAACATTGCGGT-2  ENSG00000183023          1.024897           high\n",
       "4   AAACCAACATTGCGGT-2  ENSG00000115355          1.024897           high\n",
       "5   AAACCAACATTGCGGT-2  ENSG00000172005          1.024897           high\n",
       "6   AAACCAACATTGCGGT-2  ENSG00000172985          1.024897           high\n",
       "7   AAACCAACATTGCGGT-2  ENSG00000152127          1.520305           high\n",
       "8   AAACCAACATTGCGGT-2  ENSG00000157827          1.520305           high\n",
       "9   AAACCAACATTGCGGT-2  ENSG00000236283          1.024897           high\n",
       "10  AAACCAACATTGCGGT-2  ENSG00000057019          1.024897           high\n",
       "11  AAACCAACATTGCGGT-2  ENSG00000283154          1.024897           high\n",
       "12  AAACCAACATTGCGGT-2  ENSG00000144959          1.850096           high\n",
       "13  AAACCAACATTGCGGT-2  ENSG00000169760          1.520305           high\n",
       "14  AAACCAACATTGCGGT-2  ENSG00000002587          1.024897           high\n",
       "15  AAACCAACATTGCGGT-2  ENSG00000250137          1.520305           high\n",
       "16  AAACCAACATTGCGGT-2  ENSG00000184305          1.850096           high\n",
       "17  AAACCAACATTGCGGT-2  ENSG00000109323          1.024897           high\n",
       "18  AAACCAACATTGCGGT-2  ENSG00000287292          1.024897           high\n",
       "19  AAACCAACATTGCGGT-2  ENSG00000112902          1.024897           high\n",
       "20  AAACCAACATTGCGGT-2  ENSG00000113361          2.603257           high\n",
       "21  AAACCAACATTGCGGT-2  ENSG00000185305          1.024897           high\n",
       "22  AAACCAACATTGCGGT-2  ENSG00000069020          1.024897           high\n",
       "23  AAACCAACATTGCGGT-2  ENSG00000145819          2.295968           high\n",
       "24  AAACCAACATTGCGGT-2  ENSG00000228412          1.850096           high\n",
       "25  AAACCAACATTGCGGT-2  ENSG00000112576          1.850096           high\n",
       "26  AAACCAACATTGCGGT-2  ENSG00000177706          1.024897           high\n",
       "27  AAACCAACATTGCGGT-2  ENSG00000106415          1.024897           high\n",
       "28  AAACCAACATTGCGGT-2  ENSG00000105855          3.325113           high\n",
       "29  AAACCAACATTGCGGT-2  ENSG00000136237          1.520305           high\n",
       "30  AAACCAACATTGCGGT-2  ENSG00000287523          2.461370           high\n",
       "31  AAACCAACATTGCGGT-2  ENSG00000106258          1.024897           high\n",
       "32  AAACCAACATTGCGGT-2  ENSG00000081800          1.024897           high\n",
       "33  AAACCAACATTGCGGT-2  ENSG00000196511          1.520305           high\n",
       "34  AAACCAACATTGCGGT-2  ENSG00000253773          1.520305           high\n",
       "35  AAACCAACATTGCGGT-2  ENSG00000253438          2.097679           high\n",
       "36  AAACCAACATTGCGGT-2  ENSG00000269900          1.024897           high\n",
       "37  AAACCAACATTGCGGT-2  ENSG00000226337          1.024897           high\n",
       "38  AAACCAACATTGCGGT-2  ENSG00000119125          2.097679           high\n",
       "39  AAACCAACATTGCGGT-2  ENSG00000107611          1.024897           high\n",
       "40  AAACCAACATTGCGGT-2  ENSG00000197746          1.024897           high\n",
       "41  AAACCAACATTGCGGT-2  ENSG00000185737          1.024897           high"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2_val_path = data_root / 'splits' / 'batch2_val_filtered.tsv'\n",
    "test_df = pd.read_csv(b2_val_path, sep='\\t', nrows=42)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the emebddings from scratch for this small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 barcodes\n",
      "Using 42 genes\n",
      "Recomputing embeddings:  True\n",
      "[Embedder]: No GTF data for 2 genes in barcodes_to_genes\n",
      "[Embedder]: Iterating over custom barcode to genes mapping\n",
      "[Embedder]: Computing 40 Embeddings with mode: \"single_gene_barcode\"\n",
      "[Embedder]: Using 1 barcodes\n",
      "[Embedder]: Using 40 genes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Embedder]: Computing embeddings:   8%|███▊                                              | 3/40 [00:04<00:54,  1.47s/it]/home/marw/cmscb8/preprocessing/../src/data/embedding.py:1167: UserWarning: No CNV data for AAACCAACATTGCGGT-2 and ENSG00000172985\n",
      "  warn('No CNV data for {} and {}'.format(barcode, gene_id))\n",
      "[Embedder]: Computing embeddings:  98%|███████████████████████████████████████████████▊ | 39/40 [00:59<00:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embedder]: skipped 1 embeddings missing CNV data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute all embeddings for batch 1\n",
    "test_dataset = CnvDataset(\n",
    "    root=data_root / 'embeddings' / 'batch_2' / 'dummy' ,\n",
    "    data_df=test_df,\n",
    "    fasta_path=genome_fasta,\n",
    "    gtf_path=gtf_path,\n",
    "    atac_path=overlap_path,\n",
    "    cnv_path=epiAneufinder_path,\n",
    "    force_recompute=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the last cell should look something like this:\n",
    "```\n",
    "Using 1 barcodes\n",
    "Using 42 genes\n",
    "Recomputing embeddings:  True\n",
    "[Embedder]: No GTF data for 2 genes in barcodes_to_genes\n",
    "[Embedder]: Iterating over custom barcode to genes mapping\n",
    "[Embedder]: Computing 40 Embeddings with mode: \"single_gene_barcode\"\n",
    "[Embedder]: Using 1 barcodes\n",
    "[Embedder]: Using 40 genes\n",
    "[Embedder]: Computing embeddings:   8%|███▊                                              | 3/40 [00:04<00:54,  1.47s/it]/home/marw/cmscb8/preprocessing/../src/data/embedding.py:1167: UserWarning: No CNV data for AAACCAACATTGCGGT-2 and ENSG00000172985\n",
    "  warn('No CNV data for {} and {}'.format(barcode, gene_id))\n",
    "[Embedder]: Computing embeddings:  98%|███████████████████████████████████████████████▊ | 39/40 [00:59<00:01,  1.52s/it][Embedder]: skipped 1 embeddings missing CNV data\n",
    "```\n",
    "This means, two gene were left out because there was no annotation found.\n",
    "Since we only use one barcode here, this results in 40 instead of 42 embeddings.\n",
    "During the loop we find out that there is no CNV data for the pair `AAACCAACATTGCGGT-2` and `ENSG00000172985`.\n",
    "Thus, the total number of embeddings is again reduced by 1.\n",
    "\n",
    "Finally you should find the computed embeddings at `data/embeddings/batch_2/dummy/single_gene_barcode`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the precomputed datasets you can get a brief overview of the dataset when printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'src.data.dataset.CnvDataset'> with 39 datapoints\n",
      "              barcode          gene_id  expression_count classification  \\\n",
      "0  AAACCAACATTGCGGT-2  ENSG00000186094          1.850096           high   \n",
      "1  AAACCAACATTGCGGT-2  ENSG00000162512          1.024897           high   \n",
      "2  AAACCAACATTGCGGT-2  ENSG00000231252          1.024897           high   \n",
      "3  AAACCAACATTGCGGT-2  ENSG00000152127          1.520305           high   \n",
      "4  AAACCAACATTGCGGT-2  ENSG00000115355          1.024897           high   \n",
      "\n",
      "                                      embedding_path  \n",
      "0  ../data/embeddings/batch_2/dummy/single_gene_b...  \n",
      "1  ../data/embeddings/batch_2/dummy/single_gene_b...  \n",
      "2  ../data/embeddings/batch_2/dummy/single_gene_b...  \n",
      "3  ../data/embeddings/batch_2/dummy/single_gene_b...  \n",
      "4  ../data/embeddings/batch_2/dummy/single_gene_b...  \n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again you can now access any data point by index or loop over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([0.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 10000])\n",
      "0 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "1 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "2 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "3 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "4 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "5 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "6 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "7 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "8 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "9 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "10 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "11 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "12 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "13 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "14 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "15 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "16 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "17 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "18 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "19 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "20 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "21 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "22 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "23 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "24 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "25 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "26 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "27 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "28 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "29 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "30 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "31 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "32 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "33 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "34 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "35 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "36 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "37 torch.float32\n",
      "torch.Size([7, 10000])\n",
      "38 torch.float32\n"
     ]
    }
   ],
   "source": [
    "for i, (embedding, target) in enumerate(test_dataset):\n",
    "    print(embedding.shape)\n",
    "    print(i, target.dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
