{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c7cf26",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2494f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "from torch.amp import autocast\n",
    "from torch import nn, optim\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9db2f1-61ce-40c5-913b-c05157edfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import CnvDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703160d",
   "metadata": {},
   "source": [
    "Important paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e03ee3-668e-4efb-a12d-35caa925c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_root = Path('.')\n",
    "data_root = git_root / 'data'\n",
    "assert data_root.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8b1df",
   "metadata": {},
   "source": [
    "Defining paths for batch 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c18ef7-ead4-4c87-9e70-8fe209018cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_val = data_root / 'embeddings' / 'batch_1' / 'val'\n",
    "dataset_root_train = data_root / 'embeddings' / 'batch_1' / 'train'\n",
    "dataset_root_test = data_root / 'embeddings' / 'batch_1' / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09df35c1-f306-4340-afcf-fd7ed0f75c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>expression_count</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCAACATGTCAGC-1</td>\n",
       "      <td>ENSG00000269113</td>\n",
       "      <td>0.749940</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCAACATGTCAGC-1</td>\n",
       "      <td>ENSG00000229956</td>\n",
       "      <td>1.173642</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCAACATGTCAGC-1</td>\n",
       "      <td>ENSG00000237505</td>\n",
       "      <td>0.749940</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCAACATGTCAGC-1</td>\n",
       "      <td>ENSG00000188641</td>\n",
       "      <td>0.749940</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCAACATGTCAGC-1</td>\n",
       "      <td>ENSG00000162636</td>\n",
       "      <td>0.749940</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59336</th>\n",
       "      <td>TTTGTTGGTGCCGCAA-1</td>\n",
       "      <td>ENSG00000198938</td>\n",
       "      <td>2.220852</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59337</th>\n",
       "      <td>TTTGTTGGTGCCGCAA-1</td>\n",
       "      <td>ENSG00000198840</td>\n",
       "      <td>1.968703</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59338</th>\n",
       "      <td>TTTGTTGGTGCCGCAA-1</td>\n",
       "      <td>ENSG00000198886</td>\n",
       "      <td>1.116385</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59339</th>\n",
       "      <td>TTTGTTGGTGCCGCAA-1</td>\n",
       "      <td>ENSG00000198786</td>\n",
       "      <td>1.406267</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59340</th>\n",
       "      <td>TTTGTTGGTGCCGCAA-1</td>\n",
       "      <td>ENSG00000198727</td>\n",
       "      <td>2.422053</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59341 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  barcode          gene_id  expression_count classification\n",
       "0      AAACCAACATGTCAGC-1  ENSG00000269113          0.749940            low\n",
       "1      AAACCAACATGTCAGC-1  ENSG00000229956          1.173642           high\n",
       "2      AAACCAACATGTCAGC-1  ENSG00000237505          0.749940            low\n",
       "3      AAACCAACATGTCAGC-1  ENSG00000188641          0.749940            low\n",
       "4      AAACCAACATGTCAGC-1  ENSG00000162636          0.749940            low\n",
       "...                   ...              ...               ...            ...\n",
       "59336  TTTGTTGGTGCCGCAA-1  ENSG00000198938          2.220852           high\n",
       "59337  TTTGTTGGTGCCGCAA-1  ENSG00000198840          1.968703           high\n",
       "59338  TTTGTTGGTGCCGCAA-1  ENSG00000198886          1.116385           high\n",
       "59339  TTTGTTGGTGCCGCAA-1  ENSG00000198786          1.406267           high\n",
       "59340  TTTGTTGGTGCCGCAA-1  ENSG00000198727          2.422053           high\n",
       "\n",
       "[59341 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_val_path = data_root / 'splits' / 'batch1_val_filtered.tsv'\n",
    "b1_val_df = pd.read_csv(b1_val_path, sep='\\t')\n",
    "b1_val_df\n",
    "\n",
    "b1_train_path = data_root / 'splits' / 'batch1_training_filtered.tsv'\n",
    "b1_train_df = pd.read_csv(b1_train_path, sep='\\t')\n",
    "b1_train_df\n",
    "\n",
    "# b1_test_path = data_root / 'splits' / 'batch1_test_filtered.tsv'\n",
    "# b1_test_df = pd.read_csv(b1_test_path, sep='\\t')\n",
    "# b1_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c0d08c-1938-44b4-928d-6861b35cd2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 51 barcodes\n",
      "Using 1093 genes\n",
      "No embedding files for 988 data points in data/embeddings/batch_1/val/single_gene_barcode!\n",
      "Using 356 barcodes\n",
      "Using 1595 genes\n",
      "No embedding files for 4335 data points in data/embeddings/batch_1/train/single_gene_barcode!\n"
     ]
    }
   ],
   "source": [
    "b1_val_dataset = CnvDataset(root=dataset_root_val, data_df=b1_val_df)\n",
    "\n",
    "b1_train_dataset = CnvDataset(root=dataset_root_train, data_df=b1_train_df)\n",
    "\n",
    "# b1_test_dataset = CnvDataset(root=dataset_root_test, data_df=b1_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5b391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./log/tensorboard --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hparams\n",
    "hparams = {\n",
    "    'batch_size': 32,\n",
    "    'epochs': 20,\n",
    "    'lr': 1e-3\n",
    "}\n",
    "sequ_len = 10000 ##### add correct one\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8a3f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93587a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tqdm_bar(iterable, desc):\n",
    "    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, tb_logger, name='default'):\n",
    "    \"\"\"\n",
    "    Model training function.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=hparams.get('lr', 1e-3)\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    epochs = hparams.get('epochs', 3)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    validation_loss = 0\n",
    "\n",
    "    # Riccardo\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    train_losses_avg = []\n",
    "    val_losses_avg = []\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # training\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        train_losses = []\n",
    "        \n",
    "        train_loop = create_tqdm_bar(\n",
    "            train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]'\n",
    "            )\n",
    "        for train_i, (stacked_inputs_batch, y_batch) in train_loop:\n",
    "\n",
    "            stacked_inputs_batch = stacked_inputs_batch.to(device)\n",
    "            y_batch = y_batch.to(device) # , non_blocking=True\n",
    "            #stacked_inputs_batch = stacked_inputs_batch.unsqueeze(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # with autocast(device_type=device):   \n",
    "            outputs = model(stacked_inputs_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # Update the progress bar.\n",
    "            train_loop.set_postfix(\n",
    "                curr_train_loss = \"{:.8f}\".format(train_loss / (train_i + 1)), \n",
    "                val_loss = \"{:.8f}\".format(validation_loss)\n",
    "                )\n",
    "\n",
    "            # Update the tensorboard logger.\n",
    "            tb_logger.add_scalar(\n",
    "                f'CNV_model_{name}/train_loss', loss.item(), \n",
    "                epoch * len(train_loader) + train_i\n",
    "                )\n",
    "            \n",
    "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "        train_losses_avg.append(avg_train_loss)\n",
    "    \n",
    "        # print(f\"Epoch {epoch + 1}/{epochs}, Loss: {train_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_loss = 0\n",
    "        val_loop = create_tqdm_bar(\n",
    "            val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]'\n",
    "            )\n",
    "        with torch.no_grad():\n",
    "            for val_i, (stacked_inputs_batch, y_batch) in val_loop:\n",
    "\n",
    "                stacked_inputs_batch = stacked_inputs_batch.to(device)\n",
    "                y_batch = y_batch.to(device) # , non_blocking=True\n",
    "                #stacked_inputs_batch = stacked_inputs_batch.unsqueeze(0)\n",
    "\n",
    "                # with torch.no_grad(), autocast():\n",
    "                y_pred = model(stacked_inputs_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_losses.append(loss.item())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Update the progress bar.\n",
    "                val_loop.set_postfix(\n",
    "                    val_loss = \"{:.8f}\".format(validation_loss / (val_i + 1))\n",
    "                    )\n",
    "\n",
    "                # Update the tensorboard logger.\n",
    "                tb_logger.add_scalar(\n",
    "                    f'CNV_model_{name}/val_loss', loss.item(), \n",
    "                    epoch * len(val_loader) + val_i\n",
    "                    )\n",
    "\n",
    "            avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "            val_losses_avg.append(avg_val_loss)\n",
    "            # print(f'Epoch {epoch+1}, Val loss: {avg_val_loss}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # This value is used for the progress bar of the training loop.\n",
    "        validation_loss /= len(val_loader)\n",
    "\n",
    "    plt.plot(train_losses_avg[1:], label='Train Loss')\n",
    "    plt.plot(val_losses_avg[1:], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "            \n",
    "    return avg_val_loss, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f8e2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    loss = 0\n",
    "    for dna_embedding, target in dataloader:\n",
    "        dna_embedding, target = dna_embedding.to(device), target.to(device)\n",
    "        y_hat = model(dna_embedding)\n",
    "        loss += criterion(target, y_hat).item()\n",
    "    return 1.0 / (2 * (loss / len(dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31800506",
   "metadata": {},
   "source": [
    "Setup tensorboard logging for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10aeb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb_log_path = Path('log') / 'tensorboard'\n",
    "run_number = len([\n",
    "    d for d in tb_log_path.iterdir() if d.is_dir() and d.name.startswith('run_')\n",
    "    ])\n",
    "tb_log_path = tb_log_path / '_'.join(['run', str(run_number)])\n",
    "tb_logger = SummaryWriter(tb_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632a651",
   "metadata": {},
   "source": [
    "Setup data and hparams for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b3b1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = hparams.get('batch_size', 32)\n",
    "train_loader = DataLoader(b1_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(b1_val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(b1_test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6946339",
   "metadata": {},
   "source": [
    "Select model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd8136cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.chromosome_cnn import ChromosomeCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed2ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = ChromosomeCNN(input_dim=7, seq_len=10_000, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7a498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/3]: 100%|██████████████████████████████████████| 1719/1719 [39:39<00:00,  1.38s/it, curr_train_loss=0.65059066, val_loss=0.00000000]\n",
      "Validation Epoch [1/3]: 100%|██████████████████████████████████████████████████████████████████| 249/249 [00:54<00:00,  4.55it/s, val_loss=0.00000000]\n",
      "Training Epoch [2/3]: 100%|██████████████████████████████████████| 1719/1719 [35:31<00:00,  1.24s/it, curr_train_loss=0.63151899, val_loss=0.00000000]\n",
      "Validation Epoch [2/3]: 100%|██████████████████████████████████████████████████████████████████| 249/249 [01:03<00:00,  3.91it/s, val_loss=0.00000000]\n",
      "Training Epoch [3/3]: 100%|██████████████████████████████████████| 1719/1719 [38:19<00:00,  1.34s/it, curr_train_loss=0.62795224, val_loss=0.00000000]\n",
      "Validation Epoch [3/3]: 100%|██████████████████████████████████████████████████████████████████| 249/249 [02:44<00:00,  1.51it/s, val_loss=0.00000000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.6525476136839533,\n",
       " OrderedDict([('conv1.weight',\n",
       "               tensor([[[ 1.1174e-01,  9.0178e-02, -1.0909e-01, -6.1994e-02,  2.4155e-01],\n",
       "                        [-1.5410e-01, -2.7498e-01, -2.8289e-01, -1.2038e-01, -9.8645e-02],\n",
       "                        [-2.0542e-01, -2.1390e-01,  3.7486e-01,  6.6523e-02, -2.8439e-01],\n",
       "                        ...,\n",
       "                        [ 1.7616e-01, -1.1232e-02, -2.6815e-02,  1.3544e-01, -2.5793e-02],\n",
       "                        [-4.7583e-02, -1.6473e-01, -1.9150e-01, -3.7817e-02, -1.9065e-01],\n",
       "                        [-1.2699e-01, -1.2472e-01, -7.1237e-02, -2.3430e-02, -2.7927e-04]],\n",
       "               \n",
       "                       [[ 1.4906e-01,  9.0318e-02,  8.9818e-02,  2.4933e-02, -5.9392e-02],\n",
       "                        [-1.7466e-01, -3.7642e-02, -1.4464e-01,  1.6248e-01,  1.0574e-01],\n",
       "                        [ 9.7295e-02,  1.3669e-01,  2.5616e-02, -1.0294e-01, -1.5016e-01],\n",
       "                        ...,\n",
       "                        [-1.6840e-01,  2.4106e-02,  1.1990e-01, -3.3628e-02, -1.3913e-01],\n",
       "                        [ 5.7552e-02,  1.0423e-01,  1.2586e-01, -7.8942e-02, -9.8705e-02],\n",
       "                        [ 2.5102e-02, -1.8691e-01,  5.3478e-02,  9.3866e-02,  1.0267e-01]],\n",
       "               \n",
       "                       [[-2.0079e-01,  3.2253e-02,  4.6892e-02, -2.8411e-01,  1.8844e-02],\n",
       "                        [ 2.8484e-03,  1.1284e-01, -4.0647e-02,  1.8041e-01,  3.5901e-02],\n",
       "                        [ 4.6092e-02,  6.0627e-02, -2.4439e-01,  3.1363e-01,  2.7064e-01],\n",
       "                        ...,\n",
       "                        [-6.2955e-02, -1.2887e-01, -6.8156e-02,  1.9219e-01,  2.4710e-02],\n",
       "                        [ 1.0445e-01, -4.9904e-03,  1.3726e-01, -8.9740e-02,  1.1063e-01],\n",
       "                        [ 4.3012e-02,  9.0787e-02, -8.2900e-02, -2.4427e-02, -9.3622e-03]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 1.4675e-01, -2.0887e-02,  1.1001e-02, -1.6738e-01, -2.3584e-01],\n",
       "                        [-7.2533e-02,  3.6035e-02,  2.2888e-01, -6.7406e-02,  3.1184e-01],\n",
       "                        [ 2.0120e-01, -9.1656e-02, -1.4492e-01, -4.5591e-02, -3.5006e-03],\n",
       "                        ...,\n",
       "                        [-6.6080e-02, -5.9217e-02,  9.2554e-02,  5.8520e-02,  1.2931e-01],\n",
       "                        [-1.4318e-01,  1.3880e-01,  3.4990e-02, -3.9003e-02,  1.1093e-01],\n",
       "                        [ 3.0856e-02, -1.0544e-01, -1.7768e-01,  1.0312e-02, -2.1909e-01]],\n",
       "               \n",
       "                       [[ 1.7785e-03, -2.0067e-01, -2.2087e-01,  2.6737e-01,  1.4634e-01],\n",
       "                        [ 2.4268e-01, -1.1622e-01, -3.9394e-02, -2.4889e-01,  1.7818e-01],\n",
       "                        [-9.8717e-02,  3.6748e-02, -1.0630e-01,  5.4700e-02, -2.3817e-01],\n",
       "                        ...,\n",
       "                        [-1.4491e-01, -9.3920e-02,  8.8934e-02,  6.9370e-02,  1.0013e-01],\n",
       "                        [ 1.1411e-02, -1.4890e-01, -5.4331e-02, -6.6117e-02, -7.5235e-02],\n",
       "                        [-1.6673e-01,  1.5244e-02,  1.1352e-01,  8.7832e-02,  1.0674e-01]],\n",
       "               \n",
       "                       [[-2.7489e-02,  2.0713e-01,  6.5145e-02, -2.1657e-02,  1.5816e-02],\n",
       "                        [ 1.3988e-01, -1.4214e-01, -7.1811e-02,  1.7399e-02,  3.4289e-01],\n",
       "                        [ 2.0087e-01, -8.1924e-02, -1.2885e-02, -2.6858e-02, -6.3150e-02],\n",
       "                        ...,\n",
       "                        [ 5.6096e-02, -6.4231e-02, -2.0134e-01, -1.8030e-01, -4.1146e-02],\n",
       "                        [-1.1533e-01,  8.3750e-02,  2.9024e-02,  1.7676e-01, -8.1855e-02],\n",
       "                        [-1.5043e-01, -5.2532e-02,  2.0676e-02,  2.6119e-02, -6.5873e-02]]])),\n",
       "              ('conv1.bias',\n",
       "               tensor([ 0.1582,  0.1004,  0.0835, -0.0285,  0.0063,  0.0378, -0.0763,  0.0209,\n",
       "                        0.0429, -0.0028, -0.0200, -0.0072, -0.1126,  0.0674, -0.0193,  0.1578,\n",
       "                        0.1392,  0.1211, -0.0866,  0.0335,  0.0739, -0.0134,  0.0056,  0.0537,\n",
       "                       -0.0470,  0.0892, -0.1250,  0.0440,  0.0426, -0.0277,  0.1193, -0.0904])),\n",
       "              ('conv2.weight',\n",
       "               tensor([[[-2.8718e-02, -2.3792e-02,  7.3429e-02, -6.2894e-02, -3.0041e-02],\n",
       "                        [ 5.4270e-02,  3.7584e-02, -3.4003e-02,  3.3165e-02,  8.5782e-02],\n",
       "                        [ 1.2144e-01,  6.6071e-02, -6.7054e-02,  1.7524e-02,  6.1128e-03],\n",
       "                        ...,\n",
       "                        [ 5.9822e-02,  7.3521e-02, -4.5939e-02, -3.0173e-02,  9.4993e-02],\n",
       "                        [-7.1808e-02,  1.4191e-01, -3.9229e-02,  1.3218e-01, -6.9859e-02],\n",
       "                        [ 2.7072e-02,  1.2028e-01, -7.9487e-02,  8.1889e-02,  1.5985e-01]],\n",
       "               \n",
       "                       [[ 9.4303e-02, -3.3980e-01, -8.4853e-02, -2.6728e-02,  1.8408e-01],\n",
       "                        [ 1.3457e-01,  1.7597e-01,  7.3716e-02, -1.3122e-01, -9.6330e-02],\n",
       "                        [-1.5840e-01,  1.1930e-01,  9.4959e-02,  1.1276e-01,  1.0842e-01],\n",
       "                        ...,\n",
       "                        [ 1.1124e-01,  1.8381e-02, -1.0797e-02, -1.0827e-01, -4.7582e-03],\n",
       "                        [-7.7306e-03,  9.1542e-02, -1.0756e-01,  1.1520e-01,  8.3744e-02],\n",
       "                        [-4.3086e-02, -1.6609e-02,  2.5034e-04, -1.0042e-01,  9.6543e-02]],\n",
       "               \n",
       "                       [[-6.5719e-02,  3.7816e-02, -1.0463e-01,  4.9066e-02, -9.7440e-03],\n",
       "                        [ 9.4597e-03,  4.3315e-02, -6.4621e-02, -2.2651e-02, -8.9183e-02],\n",
       "                        [-1.8061e-02, -6.5248e-02, -8.3404e-02, -3.8761e-02,  5.5226e-02],\n",
       "                        ...,\n",
       "                        [-2.5325e-02,  2.9844e-02, -4.5299e-03, -3.5633e-02, -9.6017e-02],\n",
       "                        [-3.7322e-02,  3.8591e-02, -5.4040e-02, -4.2898e-02,  6.1461e-02],\n",
       "                        [ 5.1023e-02, -2.7399e-02,  4.0626e-03,  3.6019e-02,  7.2834e-03]],\n",
       "               \n",
       "                       ...,\n",
       "               \n",
       "                       [[ 5.2581e-02,  1.1427e-01, -4.1962e-02, -1.2809e-01,  2.8534e-01],\n",
       "                        [ 1.3384e-01, -7.3982e-02, -2.2490e-02, -4.5429e-02,  9.2312e-02],\n",
       "                        [ 2.3964e-02, -2.9169e-02, -7.7017e-02,  7.1976e-02,  6.2395e-03],\n",
       "                        ...,\n",
       "                        [-1.6128e-02, -5.9967e-02,  2.1073e-02, -3.3033e-02,  1.0637e-02],\n",
       "                        [ 2.1306e-02,  1.1503e-01,  8.5722e-02, -6.1529e-02,  1.0966e-01],\n",
       "                        [-8.0272e-03, -8.8379e-02, -7.4960e-02,  2.4312e-01,  2.4726e-01]],\n",
       "               \n",
       "                       [[-1.9549e-02, -2.2561e-02,  1.4553e-02, -8.8212e-02, -9.0967e-02],\n",
       "                        [ 3.8310e-02, -7.3304e-02, -5.7437e-02, -8.0507e-02, -8.0518e-02],\n",
       "                        [-7.1853e-03, -6.9658e-02,  4.9401e-02,  4.0933e-02, -6.3313e-03],\n",
       "                        ...,\n",
       "                        [-6.7066e-02, -4.3344e-03,  4.3748e-02, -1.8546e-02, -4.3625e-03],\n",
       "                        [ 2.5299e-02,  7.0115e-03, -1.0549e-01, -6.9078e-02, -1.0410e-01],\n",
       "                        [-3.0102e-02, -5.0701e-02,  5.5606e-02, -4.2709e-02,  9.5866e-03]],\n",
       "               \n",
       "                       [[ 1.6572e-01,  1.0403e-01,  1.0151e-01,  1.6099e-01,  1.2060e-01],\n",
       "                        [ 7.1406e-03,  1.1892e-01, -9.7635e-04,  5.8128e-02,  4.1106e-02],\n",
       "                        [ 2.5196e-02, -4.7345e-02,  6.6209e-03, -6.9870e-02,  1.9685e-02],\n",
       "                        ...,\n",
       "                        [-1.3435e-01,  6.6323e-02, -6.1367e-02,  8.7911e-02, -7.7314e-02],\n",
       "                        [ 3.7764e-02,  8.4624e-02,  3.6395e-02,  1.7216e-03,  1.9328e-02],\n",
       "                        [-5.4367e-02,  1.5938e-02, -2.4427e-02, -5.8134e-02,  1.0361e-01]]])),\n",
       "              ('conv2.bias',\n",
       "               tensor([ 0.0828,  0.0839, -0.0769, -0.0307, -0.0949,  0.0719, -0.0382, -0.0680,\n",
       "                       -0.0660, -0.0179,  0.0771, -0.0950, -0.0750,  0.0704,  0.0261, -0.0091,\n",
       "                       -0.0017,  0.1099,  0.1176, -0.0074,  0.1211,  0.0483, -0.0594, -0.0971,\n",
       "                        0.0004,  0.1059,  0.0316,  0.1028, -0.0634, -0.0597, -0.1126, -0.1160,\n",
       "                        0.1704, -0.0674,  0.1128,  0.0111,  0.0532, -0.0660,  0.0091,  0.0928,\n",
       "                        0.0860,  0.0283,  0.1256,  0.0642,  0.0107,  0.1376,  0.0003, -0.0079,\n",
       "                        0.0344,  0.0320, -0.0562,  0.0728, -0.0476,  0.0505, -0.0960,  0.0711,\n",
       "                        0.0026, -0.0714,  0.1064, -0.0111,  0.0584,  0.0585, -0.0105,  0.0228])),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 0.0140, -0.0972, -0.0582, -0.1228,  0.0181,  0.1014, -0.0961, -0.0762,\n",
       "                         0.2392, -0.0626,  0.2596, -0.0102,  0.2223, -0.0484, -0.2980, -0.0361,\n",
       "                         0.1270,  0.0270,  0.1281, -0.0187, -0.1940, -0.0752,  0.0232,  0.1824,\n",
       "                         0.0579, -0.1646, -0.0566, -0.2541, -0.1675,  0.0427, -0.1580,  0.0404,\n",
       "                        -0.2074,  0.1301,  0.0763,  0.0885, -0.0350, -0.2639, -0.0189, -0.2096,\n",
       "                        -0.1163,  0.0874,  0.0917,  0.1412, -0.2198,  0.0538, -0.0070, -0.1437,\n",
       "                        -0.1473, -0.1832,  0.1405, -0.0931, -0.2018,  0.3106, -0.0777,  0.0557,\n",
       "                         0.0292, -0.0340, -0.1596, -0.0244, -0.1844,  0.1618,  0.1567, -0.3629,\n",
       "                         0.1933, -0.0644,  0.0237,  0.0774,  0.0077,  0.2335,  0.0375,  0.1269,\n",
       "                         0.0638,  0.2010, -0.0472,  0.0835,  0.1114,  0.1471, -0.2871, -0.1745,\n",
       "                         0.0290,  0.0271, -0.1306,  0.1478,  0.1402, -0.0820, -0.1531,  0.0855,\n",
       "                        -0.1895, -0.0152, -0.1548,  0.0333,  0.0407, -0.2735, -0.0145,  0.0092,\n",
       "                        -0.2053, -0.2243, -0.1643, -0.0349,  0.1025,  0.0229,  0.2912, -0.1516,\n",
       "                         0.1273,  0.0902,  0.0876,  0.0188,  0.0944,  0.2074, -0.1315, -0.0469,\n",
       "                        -0.1545, -0.2010,  0.0684,  0.1421, -0.2011, -0.1332,  0.0565, -0.0318,\n",
       "                         0.0537, -0.1022, -0.0694,  0.0126, -0.0323,  0.0389,  0.0471,  0.0431]])),\n",
       "              ('fc2.bias', tensor([0.0313])),\n",
       "              ('fc1.weight',\n",
       "               tensor([[ 1.0606e-03,  9.0200e-04, -1.1853e-03,  ..., -8.2583e-04,\n",
       "                         1.1480e-03, -1.1931e-05],\n",
       "                       [-1.1303e-03,  8.7302e-04, -1.0283e-03,  ...,  7.7086e-04,\n",
       "                         4.9749e-04,  3.8007e-04],\n",
       "                       [ 9.1558e-04, -6.3997e-04, -7.9685e-04,  ...,  1.0804e-03,\n",
       "                        -7.3648e-04,  1.0451e-03],\n",
       "                       ...,\n",
       "                       [ 7.1950e-04,  1.0073e-03,  7.6199e-04,  ..., -7.7242e-04,\n",
       "                        -5.2110e-04, -2.1619e-04],\n",
       "                       [ 6.4808e-04, -8.3339e-04,  5.6500e-04,  ..., -3.5075e-04,\n",
       "                        -4.0260e-04,  1.0303e-03],\n",
       "                       [-2.6462e-05,  8.0527e-04, -1.1568e-03,  ...,  3.2013e-05,\n",
       "                        -9.0892e-05,  6.2649e-04]])),\n",
       "              ('fc1.bias',\n",
       "               tensor([-3.2252e-04,  1.9140e-04,  5.7173e-05, -9.4684e-04,  1.7029e-05,\n",
       "                       -2.0373e-04, -1.1207e-04,  1.1697e-03,  7.2251e-04, -2.5506e-04,\n",
       "                        5.7869e-04, -4.3116e-04, -4.5892e-04, -3.6248e-04, -2.9414e-04,\n",
       "                        9.6719e-04, -7.5698e-04, -3.9814e-04,  7.3679e-04,  2.3705e-05,\n",
       "                        6.4874e-04,  5.4968e-04,  1.6753e-04,  4.3199e-04, -7.0213e-04,\n",
       "                        9.0211e-04,  4.9558e-04, -5.4069e-04, -3.4563e-04, -3.4082e-04,\n",
       "                       -8.0244e-04, -1.1837e-03, -3.5421e-04,  1.4042e-04, -6.4964e-04,\n",
       "                       -2.9599e-04,  1.0082e-03,  9.2356e-04, -1.0406e-03,  2.4655e-04,\n",
       "                        2.2605e-05, -5.1447e-04, -1.0713e-03, -1.3276e-04, -8.3251e-04,\n",
       "                       -3.5874e-04,  6.8758e-04,  8.2437e-04, -6.6403e-04,  4.6321e-04,\n",
       "                        1.1882e-03,  7.0045e-04,  1.2335e-05,  4.4160e-04, -5.4425e-04,\n",
       "                       -2.5412e-04,  1.0348e-04, -4.2571e-04,  4.3220e-04, -5.1546e-04,\n",
       "                        3.3903e-04,  1.8120e-04, -5.6936e-04,  7.3946e-05, -7.5790e-04,\n",
       "                       -7.0949e-04,  6.5641e-04, -1.0054e-03,  5.3760e-04, -2.6499e-04,\n",
       "                        1.8915e-04, -1.5181e-04,  6.6246e-04,  9.0911e-04,  1.0287e-03,\n",
       "                       -1.2304e-03,  4.9156e-04,  1.7838e-04, -9.0702e-04, -3.3403e-04,\n",
       "                        2.8739e-04,  3.3605e-04,  5.8119e-04,  2.1193e-04,  1.3024e-04,\n",
       "                       -6.3017e-04, -1.0897e-03, -3.1299e-04, -8.1084e-05,  1.1677e-03,\n",
       "                       -1.2137e-03, -7.9085e-04, -3.2035e-04, -1.0715e-03,  4.2909e-04,\n",
       "                        1.2054e-03,  6.6969e-04,  7.3541e-04,  1.2327e-03,  7.8116e-04,\n",
       "                       -5.1551e-04, -8.5305e-04,  1.2464e-03,  8.8591e-04,  5.5175e-04,\n",
       "                       -9.4784e-04, -6.7818e-04,  8.8726e-04,  1.1714e-03,  3.4016e-04,\n",
       "                       -4.4414e-04, -1.7143e-04, -2.2395e-04,  1.8133e-04,  2.2263e-04,\n",
       "                        8.0923e-04, -8.8999e-05, -1.0295e-03,  8.6032e-04, -1.1714e-03,\n",
       "                       -1.1059e-03, -1.2113e-03,  3.6356e-04,  7.6275e-04,  3.2104e-04,\n",
       "                        6.4972e-04, -8.9183e-07, -2.7962e-04]))]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_val_loss, best_model = train_model(cnn_model, train_loader, val_loader, tb_logger, name='ChromosomeCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(cnn_model, b1_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b014603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbf3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7194e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study_evaluation(train_loader, val_loader, test_loader, channel_variable_counts, seq_len, num_epochs):\n",
    "\n",
    "    print(\"Training with all channels intact...\")\n",
    "    num_channels = 7\n",
    "    \n",
    "    full_train_loader = full_study(train_loader)\n",
    "    full_val_loader = full_study(val_loader)\n",
    "    full_test_loader = full_study(test_loader)\n",
    "    \n",
    "    model = ChromosomeCNN(input_dim = num_channels, seq_len = seq_len, output_dim = 1).to(device)\n",
    "    baseline_loss = train_(model, full_train_loader, full_val_loader, num_epochs)\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "    }, 'baseline_model.pth')\n",
    "    \n",
    "    baseline_test = test_model(\"baseline_model.pth\", full_test_loader, num_channels, seq_len)\n",
    "\n",
    "    for channel_idx in range(3):\n",
    "        print(f\"\\nAblating channel {channel_idx}...\")\n",
    "        \n",
    "        remaining_channels = [i for i in range(3) if i != channel_idx]\n",
    "        remaining_variables = sum(channel_variable_counts[i] for i in remaining_channels)\n",
    "        print(\"remaing variables\", remaining_variables)\n",
    "        \n",
    "        model = ChromosomeCNN(input_dim = remaining_variables, seq_len = seq_len, output_dim = 1).to(device)\n",
    "        \n",
    "        ablated_train_loader = create_ablated_dataloader(train_loader, channel_idx, channel_variable_counts)\n",
    "        ablated_val_loader = create_ablated_dataloader(val_loader, channel_idx, channel_variable_counts)\n",
    "        ablated_test_loader = create_ablated_dataloader(test_loader, channel_idx, channel_variable_counts)\n",
    "\n",
    "        \n",
    "        model_ablated = ChromosomeCNN(input_dim=remaining_variables, seq_len=seq_len, output_dim=1).to(device)\n",
    "        ablated_model_name = f\"ablated_model_channel_{channel_idx}\"\n",
    "        \n",
    "        ablated_loss = train_(model_ablated, ablated_train_loader, ablated_val_loader, epochs)#, ablated_model_name)\n",
    "        \n",
    "        ablated_model_filename = f'ablated_model_channel_{channel_idx}.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model_ablated.state_dict(),\n",
    "        }, ablated_model_filename)\n",
    "\n",
    "        results = {}\n",
    "        results[f\"Ablated Channel {channel_idx}\"] = test_model(\n",
    "            f\"{ablated_model_name}.pth\", ablated_test_loader, remaining_variables, seq_len\n",
    "        )\n",
    "        \n",
    "        \n",
    "        print(f\"Loss after ablating channel {channel_idx}: {ablated_loss:.4f}\")\n",
    "        print(f\"Performance drop: {baseline_loss - ablated_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed25909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_path, test_loader, total_variables, seq_len):\n",
    "\n",
    "    model = ChromosomeCNN(input_dim=total_variables, seq_len=seq_len, output_dim=1).to(device)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    input_tensor = torch.zeros(1, model.input_dim, model.seq_len).to(device)\n",
    "    model(input_tensor)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    test_losses = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for stacked_inputs_batch, y_batch in test_loader:\n",
    "            stacked_inputs_batch = stacked_inputs_batch.to(device)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "            #stacked_inputs_batch = stacked_inputs_batch.unsqueeze(0)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(stacked_inputs_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "                all_predictions.append(outputs.cpu().numpy())\n",
    "                all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "    print(f\"Test MSE: {avg_test_loss:.4f}\")\n",
    "\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    probabilities = 1 / (1 + np.exp(-all_predictions))  # Sigmoid function\n",
    "    predicted_classes = (probabilities >= 0.5).astype(int)  # Convert to 0 or 1 based on threshold\n",
    "\n",
    "    # Compute accuracy and other metrics\n",
    "    accuracy = accuracy_score(all_labels, predicted_classes)\n",
    "    precision = precision_score(all_labels, predicted_classes)\n",
    "    recall = recall_score(all_labels, predicted_classes)\n",
    "    f1 = f1_score(all_labels, predicted_classes)\n",
    "    auc = roc_auc_score(all_labels, probabilities)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'AUC: {auc:.4f}')\n",
    "    \n",
    "    return avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c3795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with all channels intact...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4119696/1265460881.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/vol/storage/shared/miniforge3/envs/ssb/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 4  \n",
    "cnv_dim = 2        \n",
    "chromatin_dim = 1  \n",
    "expression_dim = 1\n",
    "seq_len=10_000\n",
    "\n",
    "ablation_study_evaluation(train_loader, val_loader, test_loader, channel_variable_counts=[embedding_dim, cnv_dim, chromatin_dim], seq_len=seq_len, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6733641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#correct = 0\n",
    "#total = 0\n",
    "#with torch.no_grad():\n",
    "#    for X_batch, y_batch in test_loader:\n",
    "#        X_batch, y_batch = X_batch.to(device).unsqueeze(1), y_batch.to(device).unsqueeze(1)\n",
    "#        outputs = model(X_batch)\n",
    "#        predictions = (outputs > 0.5).float()\n",
    "#        correct += (predictions == y_batch).sum().item()\n",
    "#        total += y_batch.size(0)\n",
    "\n",
    "#accuracy = correct / total\n",
    "#print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(best_model)\n",
    "#model.eval()\n",
    "#test_losses = []\n",
    "#y_preds = []\n",
    "#y_actuals = []\n",
    "\n",
    "#scaler = GradScaler()\n",
    "\n",
    "#for X_batch, cnv_batch, y_batch in test_loader:\n",
    "\n",
    "#    X_batch = X_batch.unsqueeze(1).to(device, non_blocking=True)\n",
    "#    cnv_batch = cnv_batch.to(device)\n",
    "#    y_batch = y_batch.to(device, non_blocking=True)\n",
    "    \n",
    "#    with torch.no_grad(), autocast():\n",
    "#        y_pred = model(X_batch, cnv_batch)\n",
    "#        lossV = criterion(y_pred, y_batch)\n",
    "        \n",
    "#        y_preds.extend(y_pred.cpu().numpy())\n",
    "#        y_actuals.extend(y_batch.cpu().numpy())\n",
    "#        test_losses.append(lossV.item())\n",
    "\n",
    "#avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "#print(f'Test MSE: {avg_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model):\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"{:<50} {:<30} {:<15} {:<15}\".format(\"Layer Name\", \"Shape\", \"Parameters\", \"Trainable\"))\n",
    "    print(\"-\" * 110)\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "    lm_params = 0\n",
    "    lm_trainable_params = 0\n",
    "    lm_layers = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        param = parameter.numel()\n",
    "        total_params += param\n",
    "        # Check if the parameter is trainable\n",
    "        trainable = parameter.requires_grad\n",
    "        trainable_param = param if trainable else 0\n",
    "        total_trainable_params += trainable_param\n",
    "        print(\"{:<50} {:<30} {:<15} {:<15}\".format(name, str(parameter.size()), param, trainable_param))\n",
    "    print(\"-\" * 110)\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "    print(f\"Trainable Parameters: {total_trainable_params}\")\n",
    "\n",
    "#model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc12ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736c759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4556a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
