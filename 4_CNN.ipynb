{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2494f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "618d4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/fragments2.tsv', 'r') as file:\n",
    "#    for i in range(1000):\n",
    "#        print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9215be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('data/fragments1.tsv', sep='\\t', skiprows=51)\n",
    "#df = pd.read_csv('data/fragments2.tsv', sep='\\t', skiprows=51, header=None)\n",
    "\n",
    "#df.columns = ['Chromosome', 'Start', 'End', 'Barcode', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fec05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n",
    "#df_subset = df.head(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf95396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD EMBEDDINGS CREATION        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8b6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddingsTot = embed()  ## dont run, first add embeddings creation\n",
    "\n",
    "#embeddings = embeddingsTot[0]\n",
    "#cnv = embeddingsTot[1]\n",
    "#open_cromatin = embeddingsTot[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041ac57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 6000\n",
    "num_samples = 100\n",
    "\n",
    "embeddings = np.random.rand(num_samples, seq_len, 4)  # 100 samples, each of length 6000 and 4 features\n",
    "cnv = np.random.rand(num_samples, seq_len, 2)  # 100 samples, each of length 6000 and 4 features\n",
    "open_cromatin = np.random.rand(num_samples, seq_len, 1)  # 100 samples, each of length 6000 and 4 features\n",
    "gene_expression = np.random.rand(num_samples, 1)\n",
    "\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float32) if not isinstance(embeddings, torch.Tensor) else embeddings\n",
    "cnv = torch.tensor(cnv, dtype=torch.float32) if not isinstance(cnv, torch.Tensor) else cnv\n",
    "open_cromatin = torch.tensor(open_cromatin, dtype=torch.float32) if not isinstance(open_cromatin, torch.Tensor) else open_cromatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bb53d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aliprandi\\anaconda3\\envs\\tp\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == \"__main__\":\n",
      "C:\\Users\\Aliprandi\\anaconda3\\envs\\tp\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Aliprandi\\anaconda3\\envs\\tp\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "class ChromosomeDataset(Dataset):\n",
    "    def __init__(self, embeddings, cnv_data, open_cromatin, gene_expression):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.cnv_data = torch.tensor(cnv_data, dtype=torch.float32)\n",
    "        self.open_cromatin = torch.tensor(open_cromatin, dtype=torch.float32)\n",
    "        self.gene_expression = torch.tensor(gene_expression, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embeddings = self.embeddings[idx]\n",
    "        cnv = self.cnv_data[idx]\n",
    "        open_cromatin = self.open_cromatin[idx]\n",
    "        gene_expression = self.gene_expression[idx]\n",
    "        \n",
    "        return embeddings, cnv, open_cromatin, gene_expression\n",
    "\n",
    "dataset = ChromosomeDataset(embeddings, cnv, open_cromatin, gene_expression)\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.3 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size,test_size])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848602e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2380f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedDataset(Dataset):\n",
    "    def __init__(self, ablated_inputs, gene_expression):\n",
    "        self.ablated_inputs = torch.tensor(ablated_inputs, dtype=torch.float32)\n",
    "        self.gene_expression = torch.tensor(gene_expression, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ablated_inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ablated_inputs = self.ablated_inputs[idx]\n",
    "        gene_expression = self.gene_expression[idx]\n",
    "        \n",
    "        return ablated_inputs, gene_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04fd83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ChromosomeCNN(nn.Module):\n",
    "    def __init__(self,  input_dim, seq_len, output_dim):\n",
    "        super(ChromosomeCNN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.fc1 = None \n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def initialize_fc1(self, x):\n",
    "\n",
    "        if self.fc1 is None: \n",
    "            flattened_size = x.shape[1] * x.shape[2] \n",
    "            self.fc1 = nn.Linear(flattened_size, 128).to(x.device)     \n",
    "    \n",
    "    def forward(self, inputs_seq):\n",
    "        \n",
    "        x = inputs_seq.permute(0, 2, 1)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        if self.fc1 is None:\n",
    "\n",
    "            fc1_input_size = x.shape[1]\n",
    "            self.fc1 = nn.Linear(fc1_input_size, 128)\n",
    "                \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b284da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ablated_dataloader(loader, channel_to_remove, channel_variable_counts):\n",
    "    ablated_dataloader = []\n",
    "    \n",
    "    for batch in loader:\n",
    "                    \n",
    "        inputs = batch[:-1]\n",
    "        targets = batch[-1]\n",
    "       \n",
    "        ablated_inputs = ablation_study(inputs, channel_to_remove, channel_variable_counts)\n",
    "        #ablated_data.append((ablated_inputs, targets))  # Keep targets intact\n",
    "        ablated_dataloader = StackedDataset(ablated_inputs, targets)\n",
    "        \n",
    "    return ablated_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7625a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_study(loader):\n",
    "    full_dataloader = []\n",
    "    \n",
    "    for batch in loader:\n",
    "               \n",
    "        inputs = batch[:-1]\n",
    "        targets = batch[-1]\n",
    "        \n",
    "        embeddings, cnv, open_cromatin = inputs\n",
    "       \n",
    "        _inputs = (cnv, open_cromatin)\n",
    "        stacked_inputs = torch.cat(_inputs, dim=-1)\n",
    "\n",
    "        full_dataloader = StackedDataset(stacked_inputs, targets)\n",
    "        \n",
    "    return full_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c67184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study(inputs, channel_to_remove, channel_variable_counts):\n",
    "\n",
    "    embeddings, cnv, open_cromatin = inputs\n",
    "    \n",
    "    if channel_to_remove == 0:\n",
    "        # Ablating embeddings: remove embeddings\n",
    "        ablated_inputs = (cnv, open_cromatin)\n",
    "    elif channel_to_remove == 1:\n",
    "        # Ablating cnv: remove cnv\n",
    "        ablated_inputs = (embeddings, open_cromatin)\n",
    "    elif channel_to_remove == 2:\n",
    "        # Ablating open_cromatin: remove open_cromatin\n",
    "        ablated_inputs = (embeddings, cnv)\n",
    "        \n",
    "    stacked_inputs = torch.cat(ablated_inputs, dim=-1)\n",
    "\n",
    "    return stacked_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93587a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sequ_len = 6000 ##### add correct one\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "def train_(model, train_loader, val_loader, epochs):\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses_avg = []\n",
    "    val_losses_avg = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for stacked_inputs_batch, y_batch in train_loader:\n",
    "\n",
    "            stacked_inputs_batch = stacked_inputs_batch.to(device)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "            stacked_inputs_batch = stacked_inputs_batch.unsqueeze(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():   \n",
    "                outputs = model(stacked_inputs_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        for stacked_inputs_batch, y_batch in val_loader:\n",
    "\n",
    "            stacked_inputs_batch = stacked_inputs_batch.to(device)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "            stacked_inputs_batch = stacked_inputs_batch.unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad(), autocast():\n",
    "                y_pred = model(stacked_inputs_batch)\n",
    "                lossV = criterion(y_pred, y_batch)\n",
    "                val_losses.append(lossV.item())\n",
    "\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        val_losses_avg.append(avg_val_loss)\n",
    "        print(f'Epoch {epoch+1}, Val loss: {avg_val_loss}')\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7194e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_study_evaluation(dataloader, channel_variable_counts, seq_len, num_epochs):\n",
    "\n",
    "    print(\"Training with all channels intact...\")\n",
    "    num_channels = 3\n",
    "    \n",
    "    full_train_dataset = full_study(train_dataset)\n",
    "    full_val_dataset = full_study(val_dataset)\n",
    "    full_test_dataset = full_study(test_dataset)\n",
    "    \n",
    "    model = ChromosomeCNN(input_dim = num_channels, seq_len = seq_len, output_dim = 1).to(device)\n",
    "    baseline_loss = train_(model, full_train_loader, full_val_loader, num_epochs)\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "    }, 'baseline_model.pth')\n",
    "    \n",
    "    baseline_test = test_model(\"baseline_model.pth\", full_test_loader, num_channels, seq_len)\n",
    "\n",
    "    for channel_idx in range(3):\n",
    "        print(f\"\\nAblating channel {channel_idx}...\")\n",
    "        \n",
    "        remaining_channels = [i for i in range(3) if i != channel_idx]\n",
    "        remaining_variables = sum(channel_variable_counts[i] for i in remaining_channels)\n",
    "        print(\"remaing variables\", remaining_variables)\n",
    "        \n",
    "        model = ChromosomeCNN(input_dim = remaining_variables, seq_len = seq_len, output_dim = 1).to(device)\n",
    "        \n",
    "        ablated_train_loader = create_ablated_dataloader(train_loader, channel_idx, channel_variable_counts)\n",
    "        ablated_val_loader = create_ablated_dataloader(val_loader, channel_idx, channel_variable_counts)\n",
    "        ablated_test_lo = create_ablated_dataloader(test_loader, channel_idx, channel_variable_counts)\n",
    "\n",
    "        \n",
    "        model_ablated = ChromosomeCNN(input_dim=remaining_variables, seq_len=seq_len, output_dim=1).to(device)\n",
    "        ablated_model_name = f\"ablated_model_channel_{channel_idx}\"\n",
    "        \n",
    "        ablated_loss = train_(model_ablated, ablated_train_loader, ablated_val_loader, epochs)#, ablated_model_name)\n",
    "        \n",
    "        ablated_model_filename = f'ablated_model_channel_{channel_idx}.pth'\n",
    "        torch.save({\n",
    "            'model_state_dict': model_ablated.state_dict(),\n",
    "        }, ablated_model_filename)\n",
    "\n",
    "        results = {}\n",
    "        results[f\"Ablated Channel {channel_idx}\"] = test_model(\n",
    "            f\"{ablated_model_name}.pth\", ablated_test_loader, remaining_variables, seq_len\n",
    "        )\n",
    "        \n",
    "        \n",
    "        print(f\"Loss after ablating channel {channel_idx}: {ablated_loss:.4f}\")\n",
    "        print(f\"Performance drop: {baseline_loss - ablated_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed25909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_path, test_loader, total_variables, seq_len):\n",
    "\n",
    "    model = ChromosomeCNN(input_dim=total_variables, seq_len=seq_len, output_dim=1).to(device)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    input_tensor = torch.zeros(1, model.seq_len, model.input_dim).to(device)\n",
    "    model(input_tensor)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    test_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for stacked_inputs_batch, y_batch in test_loader:\n",
    "            stacked_inputs_batch = stacked_inputs_batch.to(device)\n",
    "            y_batch = y_batch.to(device, non_blocking=True)\n",
    "            stacked_inputs_batch = stacked_inputs_batch.unsqueeze(0)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(stacked_inputs_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "    print(f\"Test MSE: {avg_test_loss:.4f}\")\n",
    "    return avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba4c3795",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with all channels intact...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aliprandi\\anaconda3\\envs\\tp\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Aliprandi\\anaconda3\\envs\\tp\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5700 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11076\\2395013266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexpression_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mablation_study_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_variable_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnv_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchromatin_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpression_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11076\\300379643.py\u001b[0m in \u001b[0;36mablation_study_evaluation\u001b[1;34m(dataloader, channel_variable_counts, seq_len, num_epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChromosomeCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mbaseline_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_train_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_val_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     torch.save({\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11076\\2086237182.py\u001b[0m in \u001b[0;36mtrain_\u001b[1;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mstacked_inputs_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mstacked_inputs_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacked_inputs_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tp\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tp\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11076\\431789495.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mablated_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mablated_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mgene_expression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgene_expression\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mablated_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgene_expression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5700 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "embedding_dim = 4  \n",
    "cnv_dim = 2        \n",
    "chromatin_dim = 1  \n",
    "expression_dim = 1\n",
    "\n",
    "ablation_study_evaluation(dataset, channel_variable_counts=[embedding_dim, cnv_dim, chromatin_dim, expression_dim], seq_len=seq_len, num_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6733641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "#correct = 0\n",
    "#total = 0\n",
    "#with torch.no_grad():\n",
    "#    for X_batch, y_batch in test_loader:\n",
    "#        X_batch, y_batch = X_batch.to(device).unsqueeze(1), y_batch.to(device).unsqueeze(1)\n",
    "#        outputs = model(X_batch)\n",
    "#        predictions = (outputs > 0.5).float()\n",
    "#        correct += (predictions == y_batch).sum().item()\n",
    "#        total += y_batch.size(0)\n",
    "\n",
    "#accuracy = correct / total\n",
    "#print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(best_model)\n",
    "#model.eval()\n",
    "#test_losses = []\n",
    "#y_preds = []\n",
    "#y_actuals = []\n",
    "\n",
    "#scaler = GradScaler()\n",
    "\n",
    "#for X_batch, cnv_batch, y_batch in test_loader:\n",
    "\n",
    "#    X_batch = X_batch.unsqueeze(1).to(device, non_blocking=True)\n",
    "#    cnv_batch = cnv_batch.to(device)\n",
    "#    y_batch = y_batch.to(device, non_blocking=True)\n",
    "    \n",
    "#    with torch.no_grad(), autocast():\n",
    "#        y_pred = model(X_batch, cnv_batch)\n",
    "#        lossV = criterion(y_pred, y_batch)\n",
    "        \n",
    "#        y_preds.extend(y_pred.cpu().numpy())\n",
    "#        y_actuals.extend(y_batch.cpu().numpy())\n",
    "#        test_losses.append(lossV.item())\n",
    "\n",
    "#avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "#print(f'Test MSE: {avg_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_summary(model):\n",
    "    print(\"Model Summary:\")\n",
    "    print(\"{:<50} {:<30} {:<15} {:<15}\".format(\"Layer Name\", \"Shape\", \"Parameters\", \"Trainable\"))\n",
    "    print(\"-\" * 110)\n",
    "    total_params = 0\n",
    "    total_trainable_params = 0\n",
    "    lm_params = 0\n",
    "    lm_trainable_params = 0\n",
    "    lm_layers = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        param = parameter.numel()\n",
    "        total_params += param\n",
    "        # Check if the parameter is trainable\n",
    "        trainable = parameter.requires_grad\n",
    "        trainable_param = param if trainable else 0\n",
    "        total_trainable_params += trainable_param\n",
    "        print(\"{:<50} {:<30} {:<15} {:<15}\".format(name, str(parameter.size()), param, trainable_param))\n",
    "    print(\"-\" * 110)\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "    print(f\"Trainable Parameters: {total_trainable_params}\")\n",
    "\n",
    "#model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc12ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736c759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4556a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp",
   "language": "python",
   "name": "tp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
